{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regularised regression</h3>\n",
    "<p>Our original squared loss function in matrix/vector notation is:\n",
    "$$ L = \\frac{1}{N}\\sum_{n=1}^N (\\mathbf{t} - \\mathbf{X}\\mathbf{w})^T(\\mathbf{t} - \\mathbf{X}\\mathbf{w}) $$\n",
    "Here's another loss function:\n",
    "$$ L = \\lambda \\mathbf{w}^T\\mathbf{w} + \\frac{1}{N}\\sum_{n=1}^N (\\mathbf{t} - \\mathbf{X}\\mathbf{w})^T(\\mathbf{t} - \\mathbf{X}\\mathbf{w}) $$\n",
    "Recall that we're minimising this function and so (if $\\lambda>0$) this additional term will penalise large positive and negative values in $\\mathbf{w}$. $\\lambda$ controls how much influence this new term has over the original squared error term.</p>\n",
    "\n",
    "<p>Differentiating this with respect to $\\mathbf{w}$ and then setting to zero (this is a good exercise to do) results in:\n",
    "$$ (\\mathbf{X}^T\\mathbf{X} + \\lambda\\mathbf{I})\\mathbf{w} = \\mathbf{X}^T\\mathbf{t} $$\n",
    "where $\\mathbf{I}$ is a square matrix with ones on the diagonal and zeros elsewhere (the identity matrix).</p>\n",
    "\n",
    "<p>To demonstrate the effect of this additional term, we will generate some synthetic data by using a quadratic function and assing some random (normal / Gaussian) noise.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lampda 0 Mean Square Error = 0.401853821863\n",
      "lampda 0.01 Mean Square Error = 0.402069153805\n",
      "lampda 0.05 Mean Square Error = 0.402222270421\n",
      "lampda 0.1 Mean Square Error = 0.402422252313\n",
      "lampda 0.5 Mean Square Error = 0.404281986206\n",
      "lampda 1 Mean Square Error = 0.406388128037\n",
      "lampda 3 Mean Square Error = 0.411045654945\n",
      "lampda 5 Mean Square Error = 0.413105046923\n",
      "lampda 10 Mean Square Error = 0.415595633181\n",
      "lampda 20 Mean Square Error = 0.418606994769\n",
      "lampda 25 Mean Square Error = 0.4199489229\n"
     ]
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAGE1JREFUeJzt3X2UXHWZ4PFvkRcSTQQhQ5KBliAgQiPKIIwKaKPjTrrd\n",
       "Q2Zg1zl6dFxMOLiOiejMkmT2uPTi2V2GM64MnGOcHRFhHGR3EVmHgQizgLK8owE0QOhkwBDeFfUk\n",
       "TsKbz/5xb09VdXd1VaWr6t669/s5556ue+u+PLdSeZ66v999AUmSJEmSJEmSJEmSJEmSJKnOcuBR\n",
       "YAxYO818JwKvAmek4wPArcBm4CfAmpp5DwBuBh4DbgL272zIkqROmQVsBZYBc4AHgKMbzHcLcD1w\n",
       "ZjptCfCO9PUCYAvw1nT8IuC89PVa4MIOxy1JatE+Td4/iaQQPAG8AlwNrJhivtXANcALNdOeJSkc\n",
       "ALuAR4CD0/HTgSvS11cAf9Bm3JKkDmlWCA4GnqwZ30E1mdfOswLYkI7HFOtZBhwP3JOOLwaeS18/\n",
       "l45LkjLQrBBMldQnuhhYl85bSYdaC0iOFj5LcmQw1TZa2Y4kqQtmN3n/KZJO33EDJEcFtU4gaTIC\n",
       "WAQMkzQjfZekX+HbwDeB62qWeY6kD+FZYCnwfIPtbwUObxKjJOlfHA5sm/iDfEZmA9tImnbm0riz\n",
       "eNzlVM8aqgBXAl+eYr6LqJ6BtI7GncUeKVSNZh1AToxmHUCOjGYdQI6MZh1Ad0UF4nCIj0N8BWIT\n",
       "xK8h7oD4S/jYJohIhvbzZrMjgleBzwDfIzkz6DKSTt9z0vf/epplTwY+BjwEbEqnrQc2kiT+/wWs\n",
       "JOmI/nC7gUtSccXrgHcC7wbek/59GbgTuIvkR/YmqLyUzD84Amf/FfzNEZmE22UeEVSNZh1AToxm\n",
       "HUCOjGYdQI6MZh3A3osKxDKIj0BcAnF/+mv/HoiLIT4MMdB0NQyOwPCNFDBvFm6HZmAo6wByYijr\n",
       "AHJkKOsAcmQo6wBaF/MgTob4M4hvQzyTDtdC/If0vfkz2UC7C3S0Q6ELxs9EkqQ+FQMkTTvjw9tI\n",
       "mtjvSoc7gZ9CpVM/fNvOm3lPshYCSX0k5pJcMzXerv9uYF+qSf8u4H6o/LqbQWAhkKReiaXUd+i+\n",
       "g+S+bOOduncB2zr4a7+loLAQSFI3xBzg7dQn/oXA3VQT/31Q2ZlZiAkLgSR1RhxEtXnnPcDvAI9T\n",
       "/2v/sR7/2m+FhUCS2hezSTpxaxP/AST3Rxvv0L0XKr/KLMTWWQgkqblYBLyLauJ/J8ntc2rP5HkU\n",
       "Kr/JLMS9ZyGQVCaDIzCwBhbOg5174MlLYPMN9fPELOAY6s/kWQLcSzXx3w2VX/Q09O4pXN7MW9ub\n",
       "pNwYHIFVY9V77EQk47//YYjlEBdA3AzxK4gtEN+AOAfiuLQ4FFXh8mbhdkhSpyzfWF8Exoc/fxXi\n",
       "Voj/AvGv02agMun4TeckKUeiArwZOA3+9Pip5xm7Ayqn9TKqfmchkJRjUQEOA04juZ/QEMkDtW6D\n",
       "F18ADpq8zK5/7lV06g2bhqRSiQrEYRCfhLgSYjvE0xBXQZwNcWRaHJi6j2Dl1mR6qXnTOUn9JpZR\n",
       "/4t/LnAbcGv6d6zxRVuDI/Cm1bBgPuzaDdsvnXzWUOl4+qikvItDqU/886hP/Hm8WrefWAgk5U28\n",
       "ifrEP58k4Y8PW0z8HWUhkJS1GKA+8b+e+sT/qIm/qywEknotBqgm/SGSO3LeVjM8YuLvKQuBpG6L\n",
       "Q6hP/PtRn/gfNvFnykIgqdPiYOoT/xuZnPj78eZsRWUhkDRT8dvUJ/4DgO9TTfybTfy5ZiGQ1K5Y\n",
       "Sn3iX0R94v+Jib+vWAgkNRNLgfdRTfwHUZ/4f2zi72sWAkkTxRLqE/9i4AdUE/9DJv5CsRBIisXU\n",
       "J/6lTE78r2UTm3rAQiCVTxxEfeL/beB2qon/QRN/qVgIpOKL36I+8R9CfeJ/wMRfahYCqXhiEfWJ\n",
       "fwD4f1QT/yYTv2pYCKT+F4uA91JN/IcyOfG/mk1s6gMWAqn/xIHUJ/5lwB1UE/+PTPxqg4VAyr84\n",
       "gPrE/2bqE/8PTfyaAQuBlD/xRuoT/+HAndQn/leyiU0FZCGQshdvBE6lmviPAO6imvjvN/GriywE\n",
       "Uu/F/lQT/2nAkUxO/C9nFJzKx0IgdV/sR33ifwtwN9XEf5+JXxmyEEidF/sBp1BN/EcB91BN/Pea\n",
       "+JUjFgJp5uIN1Cf+twL3kiT9W0l+8b+UVXRSExYCqX2xkPrEfwz1if9eE7/6iIVAai4WAidTTfyD\n",
       "wH3UJ/49WUUnzZCFQJosFlCf+I8F7qea+O8x8atALARSmvjfQzXxvw34IfWJf3dW0UldZiFQUQ2O\n",
       "wMAaWDgPdu6BJy+BzTck78XrqU/8xwE/opr47zbxq0QKlzcj6wCUB4MjsGoMIqrDp5+Cb1wNcQfE\n",
       "LojbIb4I8X6I12UdsZShwuXNwu2Q9sbyjfVFYHw4ZyvEB0z8Up228+Y+3YhC6pw4Eo4anPq9F3dA\n",
       "5f9C5Z97G5NULBYC5VDMgjgdYiNwJ+xpcIO2Xbb7Sz2yHHgUGAPWTjPficCrwJk1074OPAf8eMK8\n",
       "o8AOYFM6LG+wTpuGSiUOglgP8VOIuyH+GGLe1H0EK7cm0yVN0PG8OQvYSvLEpDnAA8DRDea7Bbie\n",
       "+kJwKnA8kwvB+cDnW9i+haDwogJxMsTfQfwS4jKIEybPNzgCwzfCv70t+WsRkBpoO2/ObvL+SSSF\n",
       "4Il0/GpgBfDIhPlWA9eQHBXUup2kiEylUKc3qV2xAPgo8Gng9cBXgNVQeXHq+TffUD1dVFInNesj\n",
       "OBh4smZ8Rzpt4jwrgA3peKvVaDXwIHAZsH+Ly6jvxVsh/gr4KTACnAccBZUvNy4Ckrqp2RFBK0n9\n",
       "YmAd1YsYWvmlvwG4IH39ReBLwMoG847WvL4tHdRXYg5wOsmv/2OBrwHHQ2V7pmFJxTCUDl3zLmBj\n",
       "zfh6JncY/xPweDrsJOkcPr3m/WVM7iOgxfftI+hrsRTiP0HsSC/4+gjEvllHJRVcx/PmbGAbSbKe\n",
       "S+PO4nGXA2dMmLaMyYl+ac3rzwFXNVifhaDvRAXifRD/E+IXEF+FeHvWUUkl0pW8OQxsIek0Xp9O\n",
       "OycdJppYCL4FPA28RNLXcFY6/UrgIZI+guuAxQ22bSHoG/EGiD+B2AzxMMRn0id7SeqtwuXNwu1Q\n",
       "8cSxEF9Jf/3/b4jTkqMCSRkpXN4s3A4VQ8yF+COIH0A8DTEKMfFsMknZKFzeLNwO9bcYSO/w+QzE\n",
       "LRD/Jj0jSFJ+FC5vFm6H+k/sA/F7ENdCvAhxKcQxWUclqaHC5c3C7VD/iP0hzoXYAvEQxKfSZ/1K\n",
       "yrfC5c3C7VD+xfEQf5N2/l4FcYqdv1JfKVzeLNwO5VPMg/gYxF0Q2yH+I8SSrKOStFcKlzcLt0P5\n",
       "EssgLoR4HuImiBUQzW47IinfCpc3C7dD2Yt9IIYh/h7iZxD/HeItWUclqWMKlzcLt0PZiQMh/gxi\n",
       "G8SPIFbis36lIipc3izcDvVenAjxjfShL1dA/K6dv1KhFS5vFm6HeiPmQ5wFcR/E4xDnQSzKOipJ\n",
       "PVG4vFm4HequOALiL9O2/3+A+BDErKyjktRThcubhduhzotZEKdDbIR4AeIvIN6cdVSSMlO4vFm4\n",
       "HeqcOAhiPcRPIe6G+OPkegBJJdfxh9crc4MjMLAGFs6DnXvguJvhL44HPgRcC5wBlR9mHKQkdU3J\n",
       "jwgGR2DVGERUh7Uvw1f/B8QBWUcnKZcKlzcLt0PtWb6xvgiMD8M3Zh2ZpNxqO2/u040o1CmHHjr1\n",
       "9AXzexuHpCKzEORSVCAugP0aFIJdu3sbj6QisxDkTswD/g74IGxZBWdvrX9/1TbYfmkWkUkqprzf\n",
       "aiDIf4wdFIuA64CngU9AZXfSYfym1Ulz0K7dSRHYfEPGgUrKr8LlzRJ1FsdbIMYg/mtyh1BJ2iuF\n",
       "y5uF26GpxfsgnkvuCCpJM1K4vFm4HZosPp4+GOb3so5EUiEULm8WboeqogLxn9O7gx6TdTSSCqNw\n",
       "ebNwO5SIfSG+CXEPxOKso5FUKIXLm4XboeTMoLgd4hqfECapCwqXNwu2Q3FkembQhZ4ZJKlLCpY3\n",
       "C7VD8V6IZyHOzjoSSYVWoLyZKMgOxcfSM4M+mHUkkgqvIHmzqs93KCoQ50M8ATGYdTSSSqHP8+Zk\n",
       "fbxDsS/E30LcC7Ek62gklUYf582p9ekOxYEQP4D4tmcGSeqxPs2bjfXhDsUREI9BXOSZQZIy0Id5\n",
       "c3p9tkNxSnpm0DlZRyKptPosbzbXRzsUH03PDPr9rCORVGp9lDdb0wc7FBWIL6RnBh2bdTSSSq/t\n",
       "vJn3hxfk9AELgyMwsAbeMB8OOgJGfg3D74PKM1lHJqn0cpo3914OjwgGR2DVGERUh7O3JdMlKXM5\n",
       "zJszk8MdWr6xvgiMD8M3Zh2ZJLEXedPTG9u2cN7U0xfM720cktQZFoK27XqpwfTdvY1DkjrDQtC2\n",
       "DzwAa/fUT1u1DbZfmk08kjQzee9Zzlnvd8wGNsP5V8J9pyTNQbt2J0Vg8w1ZRydJ5C5vzlzOOovj\n",
       "30F8P7l2QJJyKWd5c+ZytEMxN33Q/HuzjkSSppGjvNkZOdqh+BTE97KOQpKa6EreXA48CowBa6eZ\n",
       "70TgVeDMmmlfB54Dfjxh3gOAm4HHgJuA/RusMyeFIOZD7IA4KetIJKmJjufNWcBWYBkwB3gAOLrB\n",
       "fLcA11NfCE4FjmdyIbgIOC99vRa4sMH281IIzoX4P1lHIUkt6HjefDewsWZ8XTpMdC7waeBy6gsB\n",
       "JEVkYiF4FFicvl6Sjk8lB4UgFqS3ln571pFIUgs6fmXxwcCTNeM70mkT51kBbGgjiMUkTUakfxdP\n",
       "M2/WPgN8HyoPZh2IJHXD7Cbvt5LULyY5Shg/d7XdUyujyXZGa17flg49EvsBfwp4ppCkvBpKh655\n",
       "F/VNQ+uZ3GH8T8Dj6bCT5Bf+6TXvL2PqpqHxB7ovJbdNQ3E+xBXZxiBJbel43pwNbCNJ5nNp3Fk8\n",
       "7nLgjAnTljF1Z/F4QVlHLjuL40CIn0Ecnl0MktS2ruTNYWALydlD69Np56TDRBMLwbeAp4GXSPoa\n",
       "zkqnHwD8I7k+fTT+G8RfZ7d9SdorOTjJprMy2qFYDPFziIFsti9Je81C0KHNfhnikmy2LUkzYiHo\n",
       "wCYPgXgRYmnvty1JM2Yh6MAmN0Bc1PvtSlJHWAhmuLnD0r6BRb3driR1jIVghpu7HOKC3m5TkjrK\n",
       "QjCDTR0F8QJEo1NZJakfWAhmsKmrIP68d9uTpK6wEOzlZt6W3mF0QW+2J0ldYyHYy81cC/H53mxL\n",
       "krrKQrAXmzgB4qnkKWSS1PcsBHuxiRsgPt397UhST1gI2lz9yRBPQOzb3e1IUs9YCNpc/S0Qn+zu\n",
       "NiSppywEbaz6/RBjEM2e0iZJ/cRC0OJqKxB3Qny0O+uXpMxYCFpc7TDETyBmdWf9kpQZC0ELq6xA\n",
       "/BDizM6vW5IyZyFoYZV/CPEjiH06v25JypyFoMnqZqVNQh/q7HolKTcsBE1W9xGIu5LmIUkqJAvB\n",
       "NKuaDfEYxAc6t05Jyh0LwTSrOgviVo8GJBWchaDBauamt5I4pTPrk6TcshA0WM2/h7ixM+uSpFyz\n",
       "EEyxivkQOyDeOfN1SVLuWQimWMW5EN+Z+XokqS9YCCYsvgDimeRRlJJUChaCCYuvg/hWZ0KRpL5g\n",
       "IahZdD+I5yGO6lw4kpR7befNIt9v53PAP0BlS9aBSJL23l4eEcSBED+DOKyz4UhS7tk0lC52IcRX\n",
       "OxuKJPUFCwHEEoifQxzS+XAkKffazpsFel7v4AgMrIFzj4WXd8IPjgN2ZB2VJGlmWqxsgyOwagwi\n",
       "qsOqsWS6JJVKWZuGlm+sLwLjw7D3F5JUNmU9fXThvKmnL5jf2zgkqf8UpBDs3DP19F27exuHJKnT\n",
       "2ugjWPN8fbPQyq32EUgqobabhvL+tK6g5RivuxuunQe7f5kcCWy/FDbf0NXoJCl/2sib/aHFyhb7\n",
       "QvwquaJYkkqtrJ3FnAo8DJWfZx2IJPWbohSCYWBj1kFIkjqv1aahhyFO6m4oktQXynhBWRwK8QJE\n",
       "UY5uJGkmStlHsBz4HlR+k3UgktSPilAIhgFvJSFJXbQceBQYA9ZOM9+JwKvAmS0sO0pyZ9BN6bC8\n",
       "wTqbHOLE3PS00UXTzydJpdHxPoJZwFZgGTAHeAA4usF8twDXUy0E0y17PvD5FrbfrBC8H+KeFtYj\n",
       "SWXR8T6Ck0iS+RPAK8DVwIop5lsNXAO80MaynbjyzWYhSZqhZoXgYODJmvEd6bSJ86wANqTjUTN9\n",
       "umVXAw8ClwH7tx5yHQuBJM1QsyeUtXKIcTGwjur9LcZ/6U+37AbggvT1F4EvASsbzDta8/q2dABi\n",
       "AFgM3N9CjJJUVEPpsNeaFYKngIGa8QEmP/7xBJJmH4BFJL/SX2my7PM1078G/P00MYw2mD4M3ASV\n",
       "16ZZVpKK7jb+5QcykPTBdtRsYBtJh+9cGncWj7scOKOFZZfWLPM54KoG65vmqCK+A/HxaWKRpDLq\n",
       "ypXFw8AWko7f9em0c9JhotpC0GhZgCuBh0j6CK4jaeKZSoMdirkQv4Q4qKU9kKTyKMstJmII4r6e\n",
       "RiJJ/aHoD6YZHIGBNfCWY2DPy3DHGh8+I0l1ivxgmsERWDVW/zjKVWM+jlKS6hS5aWj5xvoiMD4M\n",
       "ex2BJFUV+e6jC+dNPX3B/N7GIUnF0keFYOeeqafv2t3bOCRJvdSkj2DlVvsIJKlO0c8aWnk2/NYl\n",
       "sO2e5Ehg+6WeNSRJdYp81hBAfAriimxCkaS+UOTOYgDeT/LcA0lSSdRUttgnfUj9QOPZJan0inwd\n",
       "QRwH8Vh2oUhSXyh005DNQpLUBRYCSVKupYc4MdvbTktSSwrbNPQ7wHaoPN90TklSW/qlENgsJEld\n",
       "YiGQJOVaQOwLsRNi/6yDkaQ+UMg+gt8FHoHKL7MORJKKqB8Kgc1CklRiAXE7xAezDkSS+kQRbzHx\n",
       "hdfgQzf73AFJakkRC4EPqpekNhS5EPigeklqQSHPGqrhg+olqdP6rBD4oHpJKpuaZqGzXrKPQJKa\n",
       "KuLD688HXgNu/xV836uLJWl6bT+8vg+ahkZJCsHsX2QciCQVUh8Ugi8Ay4E5C7KORJKKqA8KwReB\n",
       "jcBrz2QdiSQVUR8UgvEjgtlPZR2JJKn30jOGVm71jCFJakkRrywevtEiIEktK2IhkCS1oei3mJAk\n",
       "dZqFQJJKzkIgSSVnIZCkkrMQSFLJWQgkqeQsBJJUchYCSSo5C4EklZyFQJJKzkIgSSXXSiFYDjwK\n",
       "jAFrp5nvROBV4MwWlj0AuBl4DLgJ8BGUkpRTs4CtwDJgDvAAcHSD+W4BrqdaCKZb9iLgvPT1WuDC\n",
       "Btv3pnNVQ1kHkBNDWQeQI0NZB5AjQ1kHkCMdv+ncSSTJ/AngFeBqYMUU860GrgFeaHHZ04Er0tdX\n",
       "AH/QbuAlNJR1ADkxlHUAOTKUdQA5MpR1AP2sWSE4GHiyZnxHOm3iPCuADel41ExvtOxi4Ln09XPp\n",
       "uCQpA80KQSuHGBcD69J5K+kw1bKVBuuLFrcjSeqC2U3efwoYqBkfIPllX+sEkmYfgEXAMElT0MRl\n",
       "D0mnQXIUsAR4FlgKPN9g+9uwSNQ6P+sAcsLPocrPosrPIrGt0yucna50GTCXxp3F4y4Hzmhh2Yuo\n",
       "nkW0jsadxZKkHBgGtpB0/K5Pp52TDhPVFoJGy0Jy+ug/4umjkiRJkqbS6kVsZfAE8BCwCbg321B6\n",
       "7usk/Uk/rplW1osRp/osRkn67Dalw/Leh5WJAeBWYDPwE2BNOr2M341Gn8Uoff7daPUitrJ4nOQL\n",
       "XkanAsdTn/xavRixaKb6LM4HPp9NOJlaArwjfb2ApPn5aMr53Wj0WbT13cjjvYZavYitTCrNZymk\n",
       "24FfTJhW1osRp/osoJzfjWdJfiAC7AIeIblGqYzfjUafBbTx3chjIWjlIrYyCZKO9fuBszOOJQ+8\n",
       "GLHeauBB4DLK0RQy0TKSI6V78LuxjOSzuDsdb/m7kcdC4HUD9U4m+ccdBv6EpIlAibJfjLgBOIyk\n",
       "aeAZ4EvZhtNzC4BvA58Fdk54r2zfjQUkt/n5LMmRQVvfjTwWglYuYiuTZ9K/LwDfIWk6K7PxixFh\n",
       "+osRy+B5qgnva5TruzGHpAj8LXBdOq2s343xz+KbVD+Ltr4beSwE9wNHUr0Q7Y+A72YZUIZeByxM\n",
       "X78e+FfUdxaW0XeBT6SvP0H1i19GS2te/yHl+W5USJo7Hia5xc24Mn43Gn0WhfhuNLoQrWwOI+kI\n",
       "eoDk1LCyfRbfAp4GXibpNzqL8l6MOPGz+CRwJcmpxQ+SJL2ytImfAvyG5P9F7emRZfxuTPVZDFPe\n",
       "74YkSZIkSZIkSZIkSZIkSZIkSZIkaTr/H+lW0OgWM6PKAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x59d4c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import urllib\n",
    "urllib.urlretrieve('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', 'winequality-red.csv')\n",
    "import numpy as np\n",
    "with open('winequality-red.csv') as f:\n",
    "    lines = (line for line in f)\n",
    "    data = np.loadtxt(lines, delimiter=';', skiprows=1)\n",
    "%matplotlib inline\n",
    "import pylab as plt\n",
    "    \n",
    "N = data.shape[0] #get tupple (numRows, numCols)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "train = data[:int(N*0.7)]\n",
    "test = data[int(N*0.7):]\n",
    "X_train = train[:,:11]\n",
    "X_train = np.c_[np.ones(train.shape[0]), X_train] # append 1s as first column\n",
    "q_train = train[:,11]\n",
    "\n",
    "X_test = test[:,:11]\n",
    "X_test = np.c_[np.ones(test.shape[0]), X_test]\n",
    "q_test = test[:,11]\n",
    "\n",
    "lambs = [0,0.01,0.05,0.1,0.5,1,3,5,10,20,25]\n",
    "errors = []\n",
    "for lamb in lambs:\n",
    "    w = np.linalg.solve(np.dot(X_train.T,X_train) + lamb*np.identity(12),np.dot(X_train.T,q_train))\n",
    "    f_test = np.dot(X_test,w)\n",
    "    meanSquareError = ((q_test-f_test)**2).mean()\n",
    "    errors += [meanSquareError]\n",
    "    print \"lampda\", lamb, \"Mean Square Error =\", meanSquareError\n",
    "    #plt.figure()\n",
    "    #plt.scatter(f_test,q_test, color='blue')\n",
    "    \n",
    "plt.plot(lambs, errors, '-o')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As $\\lambda$ increases, high values in $\\mathbf{w}$ are more heavily penalised which leads to *simpler* functions. Why do lower values correspond to simpler functions?</p>\n",
    "<p>Firstly, what does *simpler* mean?</p>\n",
    "<p>I would argue that simpler functions have smaller derivatives (first, second, etc) as they typically change more slowly. In our polynomials, the derivatives are dependent on the values of $\\mathbf{w}$. In particular our polynomial is:\n",
    "$$ t = \\sum_{d=0}^D w_d x^d $$\n",
    "and the first derivative is:\n",
    "$$ \\frac{dt}{dx} = \\sum_{d=1}^D dw_d x^{d-1} $$\n",
    "and second is:\n",
    "$$ \\frac{d^2t}{dx^2} = \\sum_{d=2}^D d(d-1)w_d x^{d-2} $$\n",
    "which in both cases increases with increasing values of $w_d$. So penalising high (positive and negative) values decreases (in general) the gradients (and gradients of gradients, etc).</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 159.  159.  159.  159.  159.  159.  159.  159.  159.  159.]]\n",
      "[    0.   168.   336.   504.   672.   840.  1008.  1176.  1344.  1512.\n",
      "  1680.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (12,1431) and (951,) not aligned: 1431 (dim 1) != 951 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a702a51ac518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mt_fold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mc_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mt_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlamb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mfold_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mcv_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold_pred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (12,1431) and (951,) not aligned: 1431 (dim 1) != 951 (dim 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "K = 10\n",
    "sizes = np.tile(np.floor(N/10),(1,K))\n",
    "print sizes\n",
    "sizes[-1] = sizes[-1] + N - sizes.sum()\n",
    "c_sizes = np.hstack((0,np.cumsum(sizes)))\n",
    "print c_sizes\n",
    "X = np.copy(train[:,:11])\n",
    "X = np.c_[np.ones(train.shape[0]), X]\n",
    "t = np.copy(train[:,11])\n",
    "X_test = np.copy(test[:,:11])\n",
    "X_test = np.c_[np.ones(test.shape[0]), X_test]\n",
    "t_test = np.copy(test[:,11])\n",
    "cv_loss = np.zeros(K)\n",
    "ind_loss = np.zeros(K)\n",
    "train_loss = np.zeros(K)\n",
    "\n",
    "for fold in range(K):\n",
    "    X_fold = X[c_sizes[fold]:c_sizes[fold+1],:]\n",
    "    X_train = np.delete(data,np.arange(c_sizes[fold],c_sizes[fold+1],1),0)\n",
    "\n",
    "    t_fold = t[c_sizes[fold]:c_sizes[fold+1]]\n",
    "    t_train = np.delete(t,np.arange(c_sizes[fold],c_sizes[fold+1],1),0)\n",
    "    print X_train.shape\n",
    "    w = np.linalg.solve(np.dot(X_train.T,X_train) + lamb*np.identity(12),np.dot(X_train.T,t_train))\n",
    "    fold_pred = np.dot(X_fold,w)\n",
    "    cv_loss[fold,k] = ((fold_pred - t_fold)**2).mean()\n",
    "    ind_pred = np.dot(X_test,w)\n",
    "    ind_loss[fold,k] = ((ind_pred - t_test)**2).mean()\n",
    "    train_pred = np.dot(X_train,w)\n",
    "    train_loss[fold,k] = ((train_pred - t_train)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
